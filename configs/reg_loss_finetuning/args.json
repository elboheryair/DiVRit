{
    "pos_encoding": true,
    "diacritizer_path": "diacritics/diacritizing/reg_loss_finetuning/outputs/base/outputs/3462462/pytorch_model.bin",
    "max_eval_examples": 100,
    "raw_model_name_or_path": "dicta-il/alephbertgimmel-small",
    "candidates_model_name_or_path": "diacritics/diacritizing/intermediate/base/outputs/outputs/2111473",
    "data_dir": "diacritics/diacritizing/",
    "output_dir": "diacritics/diacritizing/reg_loss_finetuning/outputs/base",
    "do_train": false,
    "do_eval": true,
    "do_predict": true,
    "num_train_epochs": 1,
    "max_steps": 10,
    "per_device_train_batch_size": 4,
    "logging_strategy": "steps",
    "logging_steps": 500,
    "evaluation_strategy": "steps",
    "eval_steps": 1000,
    "save_strategy": "no",
    "report_to": "none",
    "num_candidates": 3,
    "gradient_accumulation_steps": 1,
    "learning_rate": 5e-05
}