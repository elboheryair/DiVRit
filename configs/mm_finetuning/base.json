{
    "diacritizer_path": "diacritics/diacritizing/mm_finetuning/outputs/base/outputs/2523969/pytorch_model.bin",
    "sampling_func": "adaptive",
    "model_name_or_path": "diacritics/diacritizing/models/base/outputs/1186336",
    "raw_model_name_or_path": "dicta-il/alephbertgimmel-small",
    "candidates_model_name_or_path": "diacritics/diacritizing/intermediate/base/outputs/outputs/2256856",
    "data_dir": "diacritics/diacritizing/",
    "output_dir": "diacritics/diacritizing/mm_finetuning/outputs/base",
    "do_train": true,
    "num_train_epochs": 1,
    "max_steps": 100000,
    "per_device_train_batch_size": 8,
    "logging_strategy": "steps",
    "logging_steps": 500,
    "evaluation_strategy": "steps",
    "do_eval": true,
    "eval_steps": 1000,
    "save_strategy": "no",
    "report_to": "wandb",
    "num_words": 2,
    "num_candidates": 2,
    "gradient_accumulation_steps": 1,
    "learning_rate": 5e-05
}